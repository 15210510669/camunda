name: Zeebe CI

on:
  push:
    branches:
      - main
      - stable/*
      - release-*
      - trying
      - staging
    paths:
      - '.ci/docker/test/*'
      - '.github/actions/**'
      - '.github/workflows/zeebe-*'
      - 'Dockerfile'
      - 'bom/*'
      - 'build-tools/**'
      - 'clients/**'
      - 'dist/**'
      - 'parent/*'
      - 'pom.xml'
      - 'zeebe/**'
  pull_request:
    paths:
      - '.ci/docker/test/*'
      - '.github/actions/**'
      - '.github/workflows/zeebe-*'
      - 'Dockerfile'
      - 'bom/*'
      - 'build-tools/**'
      - 'clients/**'
      - 'dist/**'
      - 'parent/*'
      - 'pom.xml'
      - 'zeebe/**'
  merge_group: { }
  workflow_dispatch: { }
  workflow_call: { }

defaults:
  run:
    # use bash shell by default to ensure pipefail behavior is the default
    # see https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#exit-codes-and-error-action-preference
    shell: bash

env:
  DOCKER_PLATFORMS: "linux/amd64,linux/arm64"

jobs:
  performance-tests:
    name: Performance Tests
    runs-on: [ self-hosted, linux, amd64, "16" ]
    timeout-minutes: 30
    env:
      ZEEBE_PERFORMANCE_TEST_RESULTS_DIR: "/tmp/jmh"
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-zeebe
        with:
          go: false
          secret_vault_secretId: ${{ secrets.VAULT_SECRET_ID }}
          secret_vault_address: ${{ secrets.VAULT_ADDR }}
          secret_vault_roleId: ${{ secrets.VAULT_ROLE_ID }}
      - uses: ./.github/actions/build-zeebe
        with:
          go: false
          maven-extra-args: -T1C -PskipFrontendBuild
      - name: Create build output log file
        run: echo "BUILD_OUTPUT_FILE_PATH=$(mktemp)" >> $GITHUB_ENV
      - name: Maven Test Build
        run: >
          ./mvnw -B --no-snapshot-updates
          -P include-performance-tests
          -D skipChecks
          -T1C
          -f zeebe
          test
          | tee "${BUILD_OUTPUT_FILE_PATH}"
        env:
          LARGE_STATE_CONTROLLER_PERFORMANCE_TEST_SIZE_GB: "4"
      - name: Analyze Test Runs
        if: always()
        uses: ./.github/actions/analyze-test-runs
        with:
          buildOutputFilePath: ${{ env.BUILD_OUTPUT_FILE_PATH }}
      - name: Summarize test results
        if: always()
        run: |
          echo '## Performance Test Results' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          FILES="${ZEEBE_PERFORMANCE_TEST_RESULTS_DIR}/*.txt"
          for file in $FILES; do
            cat "${file}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          done
          echo '```' >> $GITHUB_STEP_SUMMARY
      - name: Upload test artifacts
        uses: ./.github/actions/collect-test-artifacts
        if: ${{ failure() || cancelled() }}
        with:
          name: Performance Tests
  test-summary:
    # Used by the merge queue to check all tests, including the unit test matrix.
    # New test jobs must be added to the `needs` lists!
    # This name is hard-coded in the branch rules; remember to update that if this name changes
    name: Test summary
    if: always()
    runs-on: ubuntu-latest
    needs:
      - performance-tests
    steps:
      - run: exit ${{ ((contains(needs.*.result, 'skipped') || contains(needs.*.result, 'failure')) && 1) || 0 }}
