<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <parent>
    <groupId>org.camunda.optimize</groupId>
    <artifactId>qa</artifactId>
    <version>3.1.0-alpha2</version>
  </parent>

  <artifactId>upgrade-es-schema-tests</artifactId>
  <packaging>pom</packaging>

  <properties>
    <skip.tests>true</skip.tests>
    <!-- default amount with a fresh engine -->
    <upgrade.expected.activityInstance.count>21</upgrade.expected.activityInstance.count>
    <!-- default 30 minutes -->
    <upgrade.timeout.seconds>1800</upgrade.timeout.seconds>
    <old.optimize.elasticsearch.port>9250</old.optimize.elasticsearch.port>
    <new.optimize.elasticsearch.port>9200</new.optimize.elasticsearch.port>
    <elasticsearch.snapshot.path>/usr/share/elasticsearch/essnapshots</elasticsearch.snapshot.path>
  </properties>

  <build>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-antrun-plugin</artifactId>
        <executions>
          <!-- 1. unpack Optimize versions -->
          <execution>
            <id>unpack</id>
            <goals>
              <goal>run</goal>
            </goals>
            <phase>pre-integration-test</phase>
            <configuration>
              <skip>${skip.tests}</skip>
              <target name="unpack optimize distributions">
                <!-- if executed in Jenkins, use settings.xml in Optimize root dir -->
                <property environment="env" />
                <condition property="maven-settings" value="--settings=${env.MAVEN_SETTINGS_XML}" else="">
                  <isset property="env.MAVEN_SETTINGS_XML" />
                </condition>
                <echo message="Downloading &amp; unpacking Optimize ${project.previousVersion}..." />
                <exec dir="${project.build.directory}/../../../" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="mvn dependency:unpack ${maven-settings} -pl qa/upgrade-es-schema-tests -Dartifact=org.camunda.optimize:camunda-optimize:${project.previousVersion}:tar.gz:production -DoutputDirectory=./target/${project.previousVersion} -DoverWriteReleases=true -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn" />
                </exec>
                <echo message="Optimize ${project.previousVersion} successfully unpacked." />

                <exec dir="${project.build.directory}/../../../" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="cp ./distro/src/environment/OptimizeLicense.txt ${project.build.directory}/${project.previousVersion}/environment" />
                </exec>

                <echo message="Downloading &amp; unpacking Optimize ${project.version}..." />
                <exec dir="${project.build.directory}/../../../" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="mvn dependency:unpack ${maven-settings} -pl qa/upgrade-es-schema-tests -Dartifact=org.camunda.optimize:camunda-optimize:${project.version}:tar.gz:production -DoutputDirectory=./target/${project.version} -DoverWriteReleases=true -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn" />
                </exec>
                <echo message="Optimize ${project.version} successfully unpacked." />

                <exec dir="${project.build.directory}/../../../" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="cp ./distro/src/environment/OptimizeLicense.txt ${project.build.directory}/${project.version}/environment" />
                </exec>
              </target>
            </configuration>
          </execution>
          <!-- 2. Starting CamBPM, old  and new ES through docker-compose -->
          <execution>
            <id>start-old-new-ES-and-CamBpm</id>
            <goals>
              <goal>run</goal>
            </goals>
            <phase>pre-integration-test</phase>
            <configuration>
              <skip>${skip.docker}</skip>
              <target name="Starting CamBpm and old ES through docker-compose">
                <exec dir="${project.basedir}/../.." executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="docker-compose up -d --force-recreate --renew-anon-volumes cambpm" />
                  <env key="CAMBPM_VERSION" value="${camunda.engine.version}" />
                </exec>
                <echo message="Create ES instances" />
                <!-- The old ElasticSearch docker container will automatically mount the ES data folder -->
                <exec dir="${project.basedir}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="docker-compose up -d --force-recreate --renew-anon-volumes" />
                  <env key="NEW_ES_VERSION" value="${elasticsearch.version}" />
                  <env key="OLD_ES_VERSION" value="${previous.optimize.elasticsearch.version}" />
                  <env key="ELASTICSEARCH_SNAPSHOT_PATH" value="${elasticsearch.snapshot.path}" />
                </exec>
                <echo message="Create ES instances have been created." />
              </target>
            </configuration>
          </execution>
          <!-- 3. Make sure CamBPM and ES are up and running -->
          <execution>
            <id>check-es-cambpm-is-up</id>
            <goals>
              <goal>run</goal>
            </goals>
            <phase>pre-integration-test</phase>
            <configuration>
              <skip>${skip.docker}</skip>
              <target name="check-cambpm-is-running" description="Check whether CamBPM is running">

                <echo message="Check CamBPM is running..." />
                <waitfor maxwait="30" maxwaitunit="second" checkevery="1" checkeveryunit="second">
                  <socket server="localhost" port="8080" />
                </waitfor>
                <echo message="CamBPM is running." />

                <echo message="Check new ES is running..." />
                <waitfor maxwait="30" maxwaitunit="second" checkevery="1" checkeveryunit="second">
                  <socket server="localhost" port="${new.optimize.elasticsearch.port}" />
                </waitfor>
                <waitfor maxwait="30" maxwaitunit="second" checkevery="1" checkeveryunit="second">
                  <http url="http://localhost:${new.optimize.elasticsearch.port}/_cluster/state" />
                </waitfor>
                <echo message="New ES is running." />

                <echo message="Old ES successfully started." />
                <echo message="Waiting for old ES to be fully up..." />
                <waitfor maxwait="30" maxwaitunit="second" checkevery="1" checkeveryunit="second">
                  <socket server="localhost" port="${old.optimize.elasticsearch.port}" />
                </waitfor>
                <waitfor maxwait="50" maxwaitunit="second" checkevery="1" checkeveryunit="second">
                  <http url="http://localhost:${old.optimize.elasticsearch.port}/_cluster/health?wait_for_status=yellow&amp;timeout=10s" />
                </waitfor>
                <echo message="Old ES is running." />

              </target>
            </configuration>
          </execution>
          <!-- 4. import the data to ElasticSearch from previous Optimize version -->
          <execution>
            <id>import-data-to-previous-Optimize</id>
            <goals>
              <goal>run</goal>
            </goals>
            <phase>pre-integration-test</phase>
            <configuration>
              <exportAntProperties>true</exportAntProperties>
              <skip>${skip.tests}</skip>
              <target name="Import the data to the previous Optimize version">
                <!-- ensure elasticsearch is clean -->
                <echo message="Making sure that ElasticSearch is clean by wiping all data for old ES..." />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -o /dev/null -w &quot;%{http_code}&quot; -f -XDELETE localhost:${old.optimize.elasticsearch.port}/_all" />
                </exec>
                <echo message="Successfully wiped all data from old ES!" />

                <echo message="Making sure that ElasticSearch is clean by wiping all data for new ES..." />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -o /dev/null -w &quot;%{http_code}&quot; -f -XDELETE localhost:${new.optimize.elasticsearch.port}/_all" />
                </exec>
                <echo message="Successfully wiped all data from new ES!" />

                <echo message="Removing the default environment-config so we can overwrite the ES port..." />
                <exec dir="${project.build.directory}/${project.previousVersion}" executable="/bin/bash">
                  <arg value="-c" />
                  <arg value="rm ./environment/environment-config.yaml" />
                </exec>

                <echo message="Starting Optimize ${project.previousVersion}..." />
                <exec dir="${project.build.directory}/${project.previousVersion}/" executable="${project.build.directory}/${project.previousVersion}/optimize-startup.sh" spawn="true">
                  <env key="OPTIMIZE_ELASTICSEARCH_HTTP_PORT" value="${old.optimize.elasticsearch.port}" />
                </exec>
                <echo message="Optimize ${project.previousVersion} has benn started." />

                <echo message="Waiting for Optimize to fully booted up..." />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="until $(nc -zv localhost 8090); do sleep 2; done" />
                </exec>
                <echo message="Optimize has benn booted up." />

                <echo message="Waiting for Optimize Import to finish..." />
                <sleep seconds="5" />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="until test $(curl 'http://localhost:8090/api/status' | jq '.isImporting.&quot;camunda-bpm&quot;') = &quot;false&quot;; do sleep 2; done" />
                </exec>
                <echo message="Import has been finished." />

                <!--save document counts for testing after the migration-->
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST localhost:${old.optimize.elasticsearch.port}/_refresh" />
                </exec>

                <exec outputproperty="pi_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${old.optimize.elasticsearch.port}/optimize-process-instance/_count | jq .count" />
                </exec>
                <exec outputproperty="ai_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST 'localhost:${old.optimize.elasticsearch.port}/optimize-process-instance/_search' -H 'Content-Type: application/json' -d '{&quot;size&quot;: 0,&quot;aggs&quot;: {&quot;events&quot;: {&quot;nested&quot;: {&quot;path&quot;: &quot;events&quot;},&quot;aggs&quot;: {&quot;event_count&quot;: {&quot;value_count&quot;: {&quot;field&quot;: &quot;events.id&quot;}}}}}}' | jq '.aggregations.events.doc_count'" />
                </exec>
                <exec outputproperty="var_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST 'localhost:${old.optimize.elasticsearch.port}/optimize-process-instance/_search' -H 'Content-Type: application/json' -d '{&quot;size&quot;: 0, &quot;aggs&quot;: {&quot;variables&quot;: {&quot;nested&quot;: { &quot;path&quot;: &quot;variables&quot; }, &quot;aggs&quot;: { &quot;variable_count&quot;: { &quot;value_count&quot;: { &quot;field&quot;: &quot;variables.id&quot; } } } } } }' | jq '.aggregations.variables.doc_count'" />
                </exec>
                <exec outputproperty="ut_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST 'localhost:${old.optimize.elasticsearch.port}/optimize-process-instance/_search' -H 'Content-Type: application/json' -d '{&quot;size&quot;: 0,&quot;aggs&quot;: {&quot;userTasks&quot;: {&quot;nested&quot;: {&quot;path&quot;: &quot;userTasks&quot;},&quot;aggs&quot;: {&quot;user_task_Count&quot;: {&quot;value_count&quot;: {&quot;field&quot;: &quot;userTasks.id&quot;}}}}}}' | jq '.aggregations.userTasks.doc_count'" />
                </exec>
                <exec outputproperty="di_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${old.optimize.elasticsearch.port}/optimize-decision-instance/_count | jq .count" />
                </exec>
                <exec outputproperty="pd_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${old.optimize.elasticsearch.port}/optimize-process-definition/_count | jq .count" />
                </exec>
                <exec outputproperty="dd_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${old.optimize.elasticsearch.port}/optimize-decision-definition/_count | jq .count" />
                </exec>


                <echo message="Authenticating on optimize api..." />
                <exec dir="${project.build.directory}/${project.previousVersion}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -w &quot;%{http_code}&quot; -f -H 'Content-Type: application/json' -XPOST localhost:8090/api/authentication --data-binary '{&quot;username&quot;:&quot;demo&quot;, &quot;password&quot;:&quot;demo&quot;}' -c authCookie -o authResponse" />
                </exec>
                <echo message="Authentication has been successful." />

                <echo message="Reading all reports from optimize api..." />
                <exec dir="${project.build.directory}/${project.previousVersion}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -w &quot;%{http_code}&quot; -f http://localhost:8090/api/report?orderBy=lastModified -b authCookie" />
                </exec>
                <echo message="Reports successfully read." />

                <echo message="Killing Optimize ${project.previousVersion}..." />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="pkill -f org.camunda.optimize.Main" />
                </exec>
                <echo message="Killed Optmize." />
              </target>
            </configuration>
          </execution>
          <!-- 5. Copy the data from the old ES to the new ES instance -->
          <execution>
            <id>copy-data</id>
            <goals>
              <goal>run</goal>
            </goals>
            <phase>pre-integration-test</phase>
            <configuration>
              <skip>${skip.tests}</skip>
              <target name="Start new ES version">

                <echo message="Create repository in old and new ES" />
                <exec dir="${project.build.directory}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -X PUT localhost:${old.optimize.elasticsearch.port}/_snapshot/my_backup?pretty -H 'Content-Type: application/json' -d'{ &quot;type&quot;: &quot;fs&quot;, &quot;settings&quot;: { &quot;location&quot;: &quot;${elasticsearch.snapshot.path}&quot;, &quot;compress&quot;: false } }' " />
                </exec>
                <exec dir="${project.build.directory}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -X PUT localhost:${new.optimize.elasticsearch.port}/_snapshot/my_backup?pretty -H 'Content-Type: application/json' -d'{ &quot;type&quot;: &quot;fs&quot;, &quot;settings&quot;: { &quot;location&quot;: &quot;${elasticsearch.snapshot.path}&quot;, &quot;compress&quot;: false } }' " />
                </exec>
                <echo message="Repositories successfully created." />

                <echo message="Create snapshot on old ES" />
                <exec dir="${project.build.directory}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -X PUT localhost:${old.optimize.elasticsearch.port}/_snapshot/my_backup/snapshot_1?wait_for_completion=true" />
                </exec>
                <echo message="Snapshot successfully created." />

                <!-- Both docker containers share a volume on ${elasticsearch.snapshot.path}. Thus, it's possible to immediately restore the snapshot. -->
                <echo message="Restore snapshot on new ES" />
                <exec dir="${project.build.directory}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -X POST localhost:${new.optimize.elasticsearch.port}/_snapshot/my_backup/snapshot_1/_restore?wait_for_completion=true" />
                </exec>
                <echo message="Snapshot successfully restored." />

                <echo message="Deleting snapshot..." />
                <exec dir="${project.build.directory}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -X DELETE localhost:${new.optimize.elasticsearch.port}/_snapshot/my_backup/snapshot_1?pretty" />
                </exec>
                <echo message="Snapshot deletion was successful." />

              </target>
            </configuration>
          </execution>
          <!-- 6. Perform migration -->
          <execution>
            <id>run-migration</id>
            <goals>
              <goal>run</goal>
            </goals>
            <phase>integration-test</phase>
            <configuration>
              <skip>${skip.tests}</skip>
              <target name="perform migration">
                <echo message="Removing the default environment-config so we can overwrite the ES port..." />
                <exec dir="${project.build.directory}/${project.version}" executable="/bin/bash">
                  <arg value="-c" />
                  <arg value="rm ./environment/environment-config.yaml" />
                </exec>
                <echo message="Running migration to ${project.version}..." />
                <exec dir="${project.build.directory}/${project.version}" executable="/bin/bash">
                  <arg value="-c" />
                  <arg value="set -o pipefail; ./upgrade/upgrade.sh --skip-warning | sed 's/^/[OPTIMIZE MIGRATION SCRIPT ${project.version}]: /'" />
                  <env key="OPTIMIZE_ELASTICSEARCH_HTTP_PORT" value="${new.optimize.elasticsearch.port}" />
                </exec>
                  <echo message="Starting Optimize ${project.version}..." />
                <exec dir="${project.build.directory}/${project.version}/" executable="${project.build.directory}/${project.version}/optimize-startup.sh" spawn="true">
                  <env key="OPTIMIZE_ELASTICSEARCH_HTTP_PORT" value="${new.optimize.elasticsearch.port}" />
                </exec>
                <echo message="Waiting for Optimize to start..." />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="until $(nc -zv localhost 8090); do sleep 2; done" />
                </exec>

                <echo message="Waiting for Optimize Import to finish..." />
                <sleep seconds="5" />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="until test $(curl 'http://localhost:8090/api/status' | jq '.isImporting.&quot;camunda-bpm&quot;') = &quot;false&quot;; do sleep 2; done" />
                </exec>

                <echo message="Authenticating on optimize api..." />
                <exec dir="${project.build.directory}/${project.version}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -w &quot;%{http_code}&quot; -f -H 'Content-Type: application/json' -XPOST localhost:8090/api/authentication --data-binary '{&quot;username&quot;:&quot;demo&quot;, &quot;password&quot;:&quot;demo&quot;}' -c authCookie -o authResponse" />
                </exec>

                <echo message="Reading all reports from optimize api..." />
                <exec dir="${project.build.directory}/${project.version}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -o /dev/null -w &quot;%{http_code}&quot; -f http://localhost:8090/api/report?orderBy=lastModified -b authCookie" />
                </exec>

                <!--assert document counts are the same as before the migration-->
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST localhost:${new.optimize.elasticsearch.port}/_refresh" />
                </exec>

                <exec outputproperty="post_migration_pi_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${new.optimize.elasticsearch.port}/optimize-process-instance/_count | jq .count" />
                </exec>
                <exec outputproperty="post_migration_ai_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST 'localhost:${new.optimize.elasticsearch.port}/optimize-process-instance/_search' -H 'Content-Type: application/json' -d '{&quot;size&quot;: 0,&quot;aggs&quot;: {&quot;events&quot;: {&quot;nested&quot;: {&quot;path&quot;: &quot;events&quot;},&quot;aggs&quot;: {&quot;event_count&quot;: {&quot;value_count&quot;: {&quot;field&quot;: &quot;events.id&quot;}}}}}}' | jq '.aggregations.events.doc_count'" />
                </exec>
                <exec outputproperty="post_migration_var_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST 'localhost:${new.optimize.elasticsearch.port}/optimize-process-instance/_search' -H 'Content-Type: application/json' -d '{&quot;size&quot;: 0, &quot;aggs&quot;: {&quot;variables&quot;: {&quot;nested&quot;: { &quot;path&quot;: &quot;variables&quot; }, &quot;aggs&quot;: { &quot;variable_count&quot;: { &quot;value_count&quot;: { &quot;field&quot;: &quot;variables.id&quot; } } } } } }' | jq '.aggregations.variables.doc_count'" />
                </exec>
                <exec outputproperty="post_migration_ut_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f -X POST 'localhost:${new.optimize.elasticsearch.port}/optimize-process-instance/_search' -H 'Content-Type: application/json' -d '{&quot;size&quot;: 0,&quot;aggs&quot;: {&quot;userTasks&quot;: {&quot;nested&quot;: {&quot;path&quot;: &quot;userTasks&quot;},&quot;aggs&quot;: {&quot;user_task_Count&quot;: {&quot;value_count&quot;: {&quot;field&quot;: &quot;userTasks.id&quot;}}}}}}' | jq '.aggregations.userTasks.doc_count'" />
                </exec>
                <exec outputproperty="post_migration_di_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${new.optimize.elasticsearch.port}/optimize-decision-instance/_count | jq .count" />
                </exec>
                <exec outputproperty="post_migration_pd_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${new.optimize.elasticsearch.port}/optimize-process-definition/_count | jq .count" />
                </exec>
                <exec outputproperty="post_migration_dd_count" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="curl -s -f localhost:${new.optimize.elasticsearch.port}/optimize-decision-definition/_count | jq .count" />
                </exec>

                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="echo Comparing Process Instance count ${pi_count} = ${post_migration_pi_count}; test ${pi_count} -eq ${post_migration_pi_count}" />
                </exec>
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="echo Comparing Process Definition count ${pd_count} = ${post_migration_pd_count}; test ${pd_count} -eq ${post_migration_pd_count}" />
                </exec>
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="echo Comparing Decision Instance count ${di_count} = ${post_migration_di_count}; test ${di_count} -eq ${post_migration_di_count}" />
                </exec>
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="echo Comparing Decision Definition count ${dd_count} = ${post_migration_dd_count}; test ${dd_count} -eq ${post_migration_dd_count}" />
                </exec>
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="echo Comparing User Task count ${ut_count} = ${post_migration_ut_count}; test ${ut_count} -eq ${post_migration_ut_count}" />
                </exec>
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="echo Comparing Activity Instance count ${ai_count} = ${post_migration_ai_count}; test ${ai_count} -eq ${post_migration_ai_count}" />
                </exec>
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="echo Comparing Variable count ${var_count} = ${post_migration_var_count}; test ${var_count} -eq ${post_migration_var_count}" />
                </exec>

                <echo message="Killing Optimize ${project.version}..." />
                <exec executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="pkill -f org.camunda.optimize.Main" />
                </exec>
              </target>
            </configuration>
          </execution>
          <!-- 7. Cleanup: stop all docker containers -->
          <execution>
            <id>cleanup</id>
            <goals>
              <goal>run</goal>
            </goals>
            <phase>post-integration-test</phase>
            <configuration>
              <skip>${skip.docker}</skip>
              <target name="Stop docker container">
                <echo message="Stopping CamBPM..." />
                <exec dir="${project.basedir}/../.." executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="docker-compose rm -sfv" />
                </exec>
                <echo message="CamBPM successfully stopped." />

                <echo message="Stopping ES instances..." />
                <exec dir="${project.basedir}" executable="/bin/bash" failonerror="true">
                  <arg value="-c" />
                  <arg value="docker-compose rm -sfv" />
                </exec>
                <echo message="ES instances successfully stopped." />
              </target>
            </configuration>
          </execution>
        </executions>
        <dependencies>
          <dependency>
            <groupId>ant-contrib</groupId>
            <artifactId>ant-contrib</artifactId>
            <version>1.0b3</version>
            <exclusions>
              <exclusion>
                <groupId>ant</groupId>
                <artifactId>ant</artifactId>
              </exclusion>
            </exclusions>
          </dependency>
        </dependencies>
      </plugin>
    </plugins>
  </build>

  <profiles>
    <profile>
      <id>upgrade-es-schema-tests</id>
      <properties>
        <skip.tests>false</skip.tests>
        <skip.docker>false</skip.docker>
      </properties>
    </profile>
    <profile>
      <id>static-data-upgrade-es-schema-tests</id>
      <properties>
        <skip.tests>false</skip.tests>
        <!-- amount from the 2 million process instance sample data -->
        <upgrade.expected.activityInstance.count>21932786</upgrade.expected.activityInstance.count>
      </properties>
    </profile>
  </profiles>
</project>
